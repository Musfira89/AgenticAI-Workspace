python==3.12 -- most stable version

why we using groq?

Grok is a fast AI inference. this actually provides you the access to open source LLM models for some number of
tokens, completely for free.

Okay, so this speed is the most amazing thing about grok.

here you can see for models, LLM models like llama 3.18 in the grok.
It is very, very fast when compared to all the other models.
And the reason why it is fast is that, there is something called as, language processing unit.


##section 10 -- last video ##
What does add_messages do?

" add_messages merges two list of messages updating existing message by ID by default"

Letâ€™s break it:
Imagine chatbot state stores messages like this:

[
  {"id": 1, "role": "human", "content": "Hello"},
  {"id": 2, "role": "ai", "content": "Hi! How can I help?"}
]


If the user sends another message, add_messages will merge it into the existing list:

// state 1
[
  {"id": 1, "role": "human", "content": "Hello"},
  {"id": 2, "role": "ai", "content": "Hi! How can I help?"},
  {"id": 3, "role": "human", "content": "Whatâ€™s the weather?"}
]

//state 2
[
  {"id": 1, "role": "human", "content": "Hello"},
  {"id": 2, "role": "ai", "content": "Hi! How can I help?"},
  {"id": 3, "role": "human", "content": "Whatâ€™s the weather?"}
]
merge lists using add_messages when state updates

If a new message has the same ID as an old one, it will update instead of adding a duplicate.

ðŸ‘‰This ensures:

Conversation history is append-only (new messages get added).
Unless thereâ€™s an update (same ID), in which case it replaces the old message.
Thatâ€™s why it works for human messages and AI messages together â†’ theyâ€™re just stored in one conversation list.


**âœ…State Class
class State(TypedDict): 
    messages: Annotated[list, add_messages]


State: This defines what our chatbotâ€™s state looks like.

messages:
Must be a list.
But we tell LangGraph: "When updating this list, use add_messages."

So the chatbot state will always look like:

{
  "messages": [   # list of conversation history
    {"id": 1, "role": "human", "content": "Hello"},
    {"id": 2, "role": "ai", "content": "Hi! How can I help?"}
  ]
}


**âœ…State update means?**

What does "state updates" mean?

In LangGraph, your state is like the chatbotâ€™s memory at any moment.

A state update happens when new input or output messages arrive (for example, user types something, AI replies).

So every time something new comes in â†’ we update the state.



âœ…Example:

First list (old state messages):
This is what the chatbot already remembers from earlier in the conversation.

Example:

[
  {"id": 1, "role": "human", "content": "Hello"},
  {"id": 2, "role": "ai", "content": "Hi! How can I help?"}
]


Second list (new messages):
This is the fresh message(s) coming in.

Example:

[
  {"id": 3, "role": "human", "content": "Whatâ€™s the weather?"}
]


Merging (with add_messages):
Instead of replacing the old list with the new one, we append/merge them.
After merging:

[
  {"id": 1, "role": "human", "content": "Hello"},
  {"id": 2, "role": "ai", "content": "Hi! How can I help?"},
  {"id": 3, "role": "human", "content": "Whatâ€™s the weather?"}
]

Why is this useful?
Because:
Without merging, the chatbot would forget previous messages (it would only keep the latest one).
With add_messages, we keep the whole conversation history, so the AI can respond with context.